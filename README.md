# üõ∞Ô∏è Pseudo-label Denoiser for Satellite Image Segmentation

> Denoising AutoEncoder (DAE) v√† Conditional Diffusion models ƒë·ªÉ tinh ch·ªânh pseudo-labels nhi·ªÖu trong b√†i to√°n semantic segmentation ·∫£nh v·ªá tinh, s·ª≠ d·ª•ng dataset OpenEarthMap.

---

## üìã T·ªïng quan

Trong pipeline semi-supervised semantic segmentation, pseudo-labels t·ª´ model teacher th∆∞·ªùng ch·ª©a nhi·ªÅu lo·∫°i l·ªói: pixel l·∫ª sai class, bi√™n gi·ªØa c√°c v√πng b·ªã nh√≤e, ho·∫∑c c·∫£ v√πng l·ªõn b·ªã nh·∫ßm class. Project n√†y x√¢y d·ª±ng c√°c model **denoiser** ƒë·ªÉ t·ª± ƒë·ªông s·ª≠a c√°c l·ªói ƒë√≥.

### Approach

1. **T·∫°o nhi·ªÖu nh√¢n t·∫°o** tr√™n ground truth labels (4 lo·∫°i noise m√¥ ph·ªèng l·ªói th·ª±c t·∫ø)
2. **Train denoiser** h·ªçc mapping: noisy label ‚Üí clean label (c√≥ ƒëi·ªÅu ki·ªán tr√™n RGB image)
3. **Inference**: √Åp d·ª•ng denoiser l√™n pseudo-labels t·ª´ model segmentation

### Models ƒë√£ th√≠ nghi·ªám

| # | Model | Params | Ki·∫øn tr√∫c | Best mIoU | Epochs |
|---|-------|--------|-----------|-----------|--------|
| 1 | UNet-ResNet34 | 24.46M | UNet + pretrained ResNet34 encoder | 94.88% | 58 (early stop) |
| 2 | UNet-EfficientNet-B4 | 20.23M | UNet + pretrained EfficientNet-B4 encoder | 96.00% | 95 (early stop) |
| 3 | **Lightweight DAE** ‚≠ê | **12.82M** | Custom U-Net (t·ª± thi·∫øt k·∫ø) | **97.78%** | 89/100 |
| 4 | Conditional Diffusion | 22.25M | U-Net + time embedding (DDPM) | 23.81% | 50 |
| 5 | Conditional DAE | 39.10M | Dual Encoder + Channel Attention | 89.22% | 90/100 |

> **K·∫øt lu·∫≠n:** Lightweight DAE nh·ªè nh·∫•t nh∆∞ng ƒë·∫°t k·∫øt qu·∫£ t·ªët nh·∫•t. Pretrained encoders kh√¥ng gi√∫p √≠ch v√¨ input domain (11 channels) kh√°c ImageNet (3 channels).

---

## üìÅ C·∫•u tr√∫c project

```
thietkedenoiser/
‚îú‚îÄ‚îÄ configs/                    # YAML configs cho t·ª´ng model
‚îÇ   ‚îú‚îÄ‚îÄ default.yaml            # Config chung (data, device, paths)
‚îÇ   ‚îú‚îÄ‚îÄ dae_resnet34.yaml       # UNet-ResNet34
‚îÇ   ‚îú‚îÄ‚îÄ dae_effnet.yaml         # UNet-EfficientNet-B4
‚îÇ   ‚îú‚îÄ‚îÄ dae_lightweight.yaml    # Lightweight DAE
‚îÇ   ‚îú‚îÄ‚îÄ dae_conditional.yaml    # Conditional DAE (Dual Encoder)
‚îÇ   ‚îî‚îÄ‚îÄ diffusion.yaml          # Conditional Diffusion
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Config loader (YAML + CLI overrides)
‚îÇ   ‚îú‚îÄ‚îÄ dae_model.py            # 4 DAE architectures + DAELoss
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_denoiser.py   # Conditional Diffusion model
‚îÇ   ‚îú‚îÄ‚îÄ noise_generator.py      # 4 lo·∫°i noise + mixed
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py              # DAEDataset v·ªõi noise injection on-the-fly
‚îÇ   ‚îú‚îÄ‚îÄ train_dae.py            # Training script (h·ªó tr·ª£ t·∫•t c·∫£ DAE models)
‚îÇ   ‚îú‚îÄ‚îÄ train_diffusion.py      # Diffusion training
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_dae.py         # Evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_noise.py       # Ph√¢n t√≠ch noise statistics
‚îÇ   ‚îú‚îÄ‚îÄ demo_inference.py       # Demo visualization
‚îÇ   ‚îú‚îÄ‚îÄ plot_eval.py            # Plot k·∫øt qu·∫£
‚îÇ   ‚îî‚îÄ‚îÄ run_eval.py             # Run full evaluation
‚îú‚îÄ‚îÄ checkpoints/                # Model weights (Git LFS)
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ logs/                   # Training history (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                # Evaluation metrics
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/         # Demo output images
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                # Setup environment
‚îÇ   ‚îú‚îÄ‚îÄ download_data.sh        # Download OpenEarthMap
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.sh      # Run t·∫•t c·∫£ experiments
‚îÇ   ‚îî‚îÄ‚îÄ run_all.sh              # Full pipeline
‚îî‚îÄ‚îÄ data/                       # Dataset (kh√¥ng track trong git)
    ‚îî‚îÄ‚îÄ OpenEarthMap/
```

---

## üóÇÔ∏è Dataset ‚Äî OpenEarthMap

- **Source:** [OpenEarthMap](https://open-earth-map.org/)
- **Split:** 2303 train / 500 val images
- **Size:** 512√ó512 pixels
- **GSD:** 0.25‚Äì0.5m
- **8 classes:** Bareland, Rangeland, Developed space, Road, Tree, Water, Agriculture, Building

---

## üîß C√†i ƒë·∫∑t

```bash
# Clone repo
git clone https://github.com/vuongcris4/thietkedenoiser.git
cd thietkedenoiser

# Pull checkpoints (Git LFS)
git lfs pull

# Setup Python environment
python3 -m venv venv
source venv/bin/activate
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install segmentation-models-pytorch opencv-python matplotlib pyyaml tqdm

# Download dataset
bash scripts/download_data.sh
```

---

## üöÄ Training

S·ª≠ d·ª•ng config-based training ‚Äî m·ªói model c√≥ file YAML ri√™ng:

```bash
cd src/

# Lightweight DAE (recommended ‚Äî best results)
python train_dae.py --config ../configs/dae_lightweight.yaml

# UNet-ResNet34
python train_dae.py --config ../configs/dae_resnet34.yaml

# UNet-EfficientNet-B4
python train_dae.py --config ../configs/dae_effnet.yaml

# Conditional DAE (Dual Encoder + Attention)
python train_dae.py --config ../configs/dae_conditional.yaml

# Conditional Diffusion
python train_diffusion.py --config ../configs/diffusion.yaml
```

### Override config t·ª´ CLI

```bash
# ƒê·ªïi batch size v√† learning rate
python train_dae.py --config ../configs/dae_lightweight.yaml \
    --training.batch_size 16 --training.lr 0.0005

# ƒê·ªïi noise rate range
python train_dae.py --config ../configs/dae_lightweight.yaml \
    --noise.rate_min 0.10 --noise.rate_max 0.40
```

### Output

- **Checkpoints:** `checkpoints/{model}_{noise}_{timestamp}_best.pth`
- **Training history:** `results/logs/{model}_{noise}_{timestamp}_history.json`
- **Console log:** Real-time metrics m·ªói epoch

---

## üîç Inference & Demo

Visualize k·∫øt qu·∫£ denoising: **RGB ‚Üí Noisy Label ‚Üí DAE Output ‚Üí Ground Truth**

```bash
# Quick demo v·ªõi Lightweight DAE
python src/demo_inference.py \
    --checkpoint checkpoints/dae_lightweight_mixed_20260208_122512_best.pth

# Custom demo
python src/demo_inference.py \
    --checkpoint checkpoints/dae_lightweight_mixed_20260208_122512_best.pth \
    --model lightweight \
    --noise_type mixed \
    --noise_rates 0.10 0.20 0.30 \
    --num_samples 4 \
    --output_dir results/visualizations/demo
```

| Parameter | Default | M√¥ t·∫£ |
|-----------|---------|-------|
| `--checkpoint` | *(b·∫Øt bu·ªôc)* | Path t·ªõi file `.pth` |
| `--model` | `lightweight` | `lightweight` / `unet_resnet34` / `unet_effnet` / `conditional` |
| `--noise_type` | `mixed` | `random_flip` / `boundary` / `region_swap` / `confusion` / `mixed` |
| `--noise_rates` | `0.10 0.20 0.30` | C√°c t·ª∑ l·ªá noise c·∫ßn test |
| `--num_samples` | `4` | S·ªë samples m·ªói noise rate |
| `--split` | `val` | `train` / `val` |
| `--seed` | `2026` | Random seed |

---

## üéØ C∆° ch·∫ø t·∫°o nhi·ªÖu (Noise Generation)

M·ªói sample ƒë∆∞·ª£c inject noise **on-the-fly** v·ªõi `noise_rate` random trong [5%, 30%]. Mixed noise k·∫øt h·ª£p c·∫£ 4 lo·∫°i, m·ªói lo·∫°i chi·∫øm `noise_rate/4`:

| Lo·∫°i | M√¥ t·∫£ | M√¥ ph·ªèng l·ªói |
|------|--------|---------------|
| **Random Flip** | ƒê·ªïi ng·∫´u nhi√™n class pixel l·∫ª | L·ªói prediction r·∫£i r√°c (salt-and-pepper) |
| **Boundary** | Dilate/Erode ranh gi·ªõi b·∫±ng morphological ops | L·ªói ph·ªï bi·∫øn nh·∫•t ‚Äî sai ·ªü bi√™n gi·ªØa 2 class |
| **Region Swap** | Ho√°n class c·∫£ v√πng l·ªõn (20-100px) | L·ªói nghi√™m tr·ªçng ‚Äî nh·∫ßm to√†n b·ªô 1 v√πng |
| **Confusion-based** | ƒê·ªïi class theo confusion matrix gi·∫£ l·∫≠p | Class gi·ªëng nhau visual c√≥ x√°c su·∫•t nh·∫ßm cao h∆°n |

---

## üìä K·∫øt qu·∫£ chi ti·∫øt

### Lightweight DAE ‚≠ê (Best model ‚Äî 97.78% mIoU)

```
Bareland: 98.4%  |  Rangeland: 97.2%  |  Developed: 96.8%  |  Road: 96.5%
Tree:     98.0%  |  Water:     98.1%  |  Agriculture: 97.9% |  Building: 99.3%
```

### Conditional DAE (Exp 5 ‚Äî 89.22% mIoU)

```
Bareland: 96.7%  |  Rangeland: 91.4%  |  Developed: 85.1%  |  Road: 82.5%
Tree:     87.1%  |  Water:     86.7%  |  Agriculture: 91.8% |  Building: 92.5%
```

### Key findings

1. **Model nh·ªè > model l·ªõn** ‚Äî Lightweight DAE (12.82M) th·∫Øng t·∫•t c·∫£ models l·ªõn h∆°n
2. **Pretrained kh√¥ng gi√∫p √≠ch** ‚Äî Input 11 channels kh√°c ImageNet, pretrained weights b·ªã mismatch
3. **Dual-encoder ph·ª©c t·∫°p h√≥a** ‚Äî T√°ch RGB/label encoder (39.1M) k√©m h∆°n single-encoder (12.82M)
4. **Diffusion ch∆∞a hi·ªáu qu·∫£** ‚Äî 50 epochs v·∫´n kh√¥ng h·ªôi t·ª•, approach ph·ª©c t·∫°p h∆°n nhi·ªÅu so v·ªõi DAE
5. **CE + Dice + Boundary loss** ‚Äî K·∫øt h·ª£p 3 loss gi√∫p b·∫£o to√†n ranh gi·ªõi class t·ªët

---

## ‚öôÔ∏è Loss Function

```
Total Loss = CE Loss √ó 1.0 + Dice Loss √ó 1.0 + Boundary Loss √ó 0.5
```

- **CrossEntropy Loss:** Pixel-wise classification
- **Dice Loss:** Overlap-based, x·ª≠ l√Ω class imbalance
- **Boundary Loss:** Sobel edge detection tr√™n prediction vs target, b·∫£o to√†n bi√™n

---

## üíª Hardware

| Component | Spec |
|-----------|------|
| GPU | NVIDIA L4 (23GB VRAM) |
| CPU | AMD EPYC 7R13 |
| RAM | 16GB |
| CUDA | 12.1 |
| PyTorch | 2.5.1 |
| Platform | AWS EC2 |

---

## üìÑ License

MIT License

