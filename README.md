# ğŸ›°ï¸ Pseudo-label Denoiser for Satellite Image Segmentation

> Denoising AutoEncoder (DAE) vÃ  Conditional Diffusion models Ä‘á»ƒ tinh chá»‰nh pseudo-labels nhiá»…u trong bÃ i toÃ¡n semantic segmentation áº£nh vá»‡ tinh, sá»­ dá»¥ng dataset OpenEarthMap.

**Äá»“ Ã¡n tá»‘t nghiá»‡p** â€” Tráº§n Duy VÆ°Æ¡ng (22139078) â€” HCMUTE

---

## ğŸ“‹ Tá»•ng quan

Trong pipeline semi-supervised semantic segmentation, pseudo-labels tá»« model teacher thÆ°á»ng chá»©a nhiá»u loáº¡i lá»—i: pixel láº» sai class, biÃªn giá»¯a cÃ¡c vÃ¹ng bá»‹ nhÃ²e, hoáº·c cáº£ vÃ¹ng lá»›n bá»‹ nháº§m class. Project nÃ y xÃ¢y dá»±ng cÃ¡c model **denoiser** Ä‘á»ƒ tá»± Ä‘á»™ng sá»­a cÃ¡c lá»—i Ä‘Ã³.

### Approach

1. **Táº¡o nhiá»…u nhÃ¢n táº¡o** trÃªn ground truth labels (4 loáº¡i noise mÃ´ phá»ng lá»—i thá»±c táº¿)
2. **Train denoiser** há»c mapping: noisy label â†’ clean label (cÃ³ Ä‘iá»u kiá»‡n trÃªn RGB image)
3. **Inference**: Ãp dá»¥ng denoiser lÃªn pseudo-labels tá»« model segmentation

### Models Ä‘Ã£ thÃ­ nghiá»‡m

| # | Model | Params | Kiáº¿n trÃºc | Best mIoU | Epochs |
|---|-------|--------|-----------|-----------|--------|
| 1 | UNet-ResNet34 | 24.46M | UNet + pretrained ResNet34 encoder | 94.88% | 58 (early stop) |
| 2 | UNet-EfficientNet-B4 | 20.23M | UNet + pretrained EfficientNet-B4 encoder | 96.00% | 95 (early stop) |
| 3 | **Lightweight DAE** â­ | **12.82M** | Custom U-Net (tá»± thiáº¿t káº¿) | **97.78%** | 89/100 |
| 4 | Conditional Diffusion | 22.25M | U-Net + time embedding (DDPM) | 18.86% | 20 |
| 5 | Conditional DAE | 39.10M | Dual Encoder + Channel Attention | 89.22% | 90/100 |

> **Káº¿t luáº­n:** Lightweight DAE nhá» nháº¥t nhÆ°ng Ä‘áº¡t káº¿t quáº£ tá»‘t nháº¥t. Pretrained encoders khÃ´ng giÃºp Ã­ch vÃ¬ input domain (11 channels) khÃ¡c ImageNet (3 channels).

---

## ğŸ“ Cáº¥u trÃºc project

```
thietkedenoiser/
â”œâ”€â”€ configs/                    # YAML configs cho tá»«ng model
â”‚   â”œâ”€â”€ default.yaml            # Config chung (data, device, paths)
â”‚   â”œâ”€â”€ dae_resnet34.yaml       # UNet-ResNet34
â”‚   â”œâ”€â”€ dae_effnet.yaml         # UNet-EfficientNet-B4
â”‚   â”œâ”€â”€ dae_lightweight.yaml    # Lightweight DAE
â”‚   â”œâ”€â”€ dae_conditional.yaml    # Conditional DAE (Dual Encoder)
â”‚   â””â”€â”€ diffusion.yaml          # Conditional Diffusion
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Config loader (YAML + CLI overrides)
â”‚   â”œâ”€â”€ dae_model.py            # 4 DAE architectures + DAELoss
â”‚   â”œâ”€â”€ diffusion_denoiser.py   # Conditional Diffusion model
â”‚   â”œâ”€â”€ noise_generator.py      # 4 loáº¡i noise + mixed
â”‚   â”œâ”€â”€ dataset.py              # DAEDataset vá»›i noise injection on-the-fly
â”‚   â”œâ”€â”€ train_dae.py            # Training script (há»— trá»£ táº¥t cáº£ DAE models)
â”‚   â”œâ”€â”€ train_diffusion.py      # Diffusion training
â”‚   â”œâ”€â”€ evaluate_dae.py         # Evaluation metrics
â”‚   â”œâ”€â”€ evaluate_noise.py       # PhÃ¢n tÃ­ch noise statistics
â”‚   â”œâ”€â”€ demo_inference.py       # Demo visualization
â”‚   â”œâ”€â”€ plot_eval.py            # Plot káº¿t quáº£
â”‚   â””â”€â”€ run_eval.py             # Run full evaluation
â”œâ”€â”€ checkpoints/                # Model weights (Git LFS)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ logs/                   # Training history (JSON)
â”‚   â”œâ”€â”€ metrics/                # Evaluation metrics
â”‚   â””â”€â”€ visualizations/         # Demo output images
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                # Setup environment
â”‚   â”œâ”€â”€ download_data.sh        # Download OpenEarthMap
â”‚   â”œâ”€â”€ run_experiments.sh      # Run táº¥t cáº£ experiments
â”‚   â””â”€â”€ run_all.sh              # Full pipeline
â””â”€â”€ data/                       # Dataset (khÃ´ng track trong git)
    â””â”€â”€ OpenEarthMap/
```

---

## ğŸ—‚ï¸ Dataset â€” OpenEarthMap

- **Source:** [OpenEarthMap](https://open-earth-map.org/)
- **Split:** 2303 train / 500 val images
- **Size:** 512Ã—512 pixels
- **GSD:** 0.25â€“0.5m
- **8 classes:** Bareland, Rangeland, Developed space, Road, Tree, Water, Agriculture, Building

---

## ğŸ”§ CÃ i Ä‘áº·t

```bash
# Clone repo
git clone https://github.com/vuongcris4/thietkedenoiser.git
cd thietkedenoiser

# Pull checkpoints (Git LFS)
git lfs pull

# Setup Python environment
python3 -m venv venv
source venv/bin/activate
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install segmentation-models-pytorch opencv-python matplotlib pyyaml tqdm

# Download dataset
bash scripts/download_data.sh
```

---

## ğŸš€ Training

Sá»­ dá»¥ng config-based training â€” má»—i model cÃ³ file YAML riÃªng:

```bash
cd src/

# Lightweight DAE (recommended â€” best results)
python train_dae.py --config ../configs/dae_lightweight.yaml

# UNet-ResNet34
python train_dae.py --config ../configs/dae_resnet34.yaml

# UNet-EfficientNet-B4
python train_dae.py --config ../configs/dae_effnet.yaml

# Conditional DAE (Dual Encoder + Attention)
python train_dae.py --config ../configs/dae_conditional.yaml

# Conditional Diffusion
python train_diffusion.py --config ../configs/diffusion.yaml
```

### Override config tá»« CLI

```bash
# Äá»•i batch size vÃ  learning rate
python train_dae.py --config ../configs/dae_lightweight.yaml \
    --training.batch_size 16 --training.lr 0.0005

# Äá»•i noise rate range
python train_dae.py --config ../configs/dae_lightweight.yaml \
    --noise.rate_min 0.10 --noise.rate_max 0.40
```

### Output

- **Checkpoints:** `checkpoints/{model}_{noise}_{timestamp}_best.pth`
- **Training history:** `results/logs/{model}_{noise}_{timestamp}_history.json`
- **Console log:** Real-time metrics má»—i epoch

---

## ğŸ” Inference & Demo

Visualize káº¿t quáº£ denoising: **RGB â†’ Noisy Label â†’ DAE Output â†’ Ground Truth**

```bash
# Quick demo vá»›i Lightweight DAE
python src/demo_inference.py \
    --checkpoint checkpoints/dae_lightweight_mixed_20260208_122512_best.pth

# Custom demo
python src/demo_inference.py \
    --checkpoint checkpoints/dae_lightweight_mixed_20260208_122512_best.pth \
    --model lightweight \
    --noise_type mixed \
    --noise_rates 0.10 0.20 0.30 \
    --num_samples 4 \
    --output_dir results/visualizations/demo
```

| Parameter | Default | MÃ´ táº£ |
|-----------|---------|-------|
| `--checkpoint` | *(báº¯t buá»™c)* | Path tá»›i file `.pth` |
| `--model` | `lightweight` | `lightweight` / `unet_resnet34` / `unet_effnet` / `conditional` |
| `--noise_type` | `mixed` | `random_flip` / `boundary` / `region_swap` / `confusion` / `mixed` |
| `--noise_rates` | `0.10 0.20 0.30` | CÃ¡c tá»· lá»‡ noise cáº§n test |
| `--num_samples` | `4` | Sá»‘ samples má»—i noise rate |
| `--split` | `val` | `train` / `val` |
| `--seed` | `2026` | Random seed |

---

## ğŸ¯ CÆ¡ cháº¿ táº¡o nhiá»…u (Noise Generation)

Má»—i sample Ä‘Æ°á»£c inject noise **on-the-fly** vá»›i `noise_rate` random trong [5%, 30%]. Mixed noise káº¿t há»£p cáº£ 4 loáº¡i, má»—i loáº¡i chiáº¿m `noise_rate/4`:

| Loáº¡i | MÃ´ táº£ | MÃ´ phá»ng lá»—i |
|------|--------|---------------|
| **Random Flip** | Äá»•i ngáº«u nhiÃªn class pixel láº» | Lá»—i prediction ráº£i rÃ¡c (salt-and-pepper) |
| **Boundary** | Dilate/Erode ranh giá»›i báº±ng morphological ops | Lá»—i phá»• biáº¿n nháº¥t â€” sai á»Ÿ biÃªn giá»¯a 2 class |
| **Region Swap** | HoÃ¡n class cáº£ vÃ¹ng lá»›n (20-100px) | Lá»—i nghiÃªm trá»ng â€” nháº§m toÃ n bá»™ 1 vÃ¹ng |
| **Confusion-based** | Äá»•i class theo confusion matrix giáº£ láº­p | Class giá»‘ng nhau visual cÃ³ xÃ¡c suáº¥t nháº§m cao hÆ¡n |

---

## ğŸ“Š Káº¿t quáº£ chi tiáº¿t

### Lightweight DAE â­ (Best model â€” 97.78% mIoU)

```
Bareland: 98.4%  |  Rangeland: 97.2%  |  Developed: 96.8%  |  Road: 96.5%
Tree:     98.0%  |  Water:     98.1%  |  Agriculture: 97.9% |  Building: 99.3%
```

### Conditional DAE (Exp 5 â€” 89.22% mIoU)

```
Bareland: 96.7%  |  Rangeland: 91.4%  |  Developed: 85.1%  |  Road: 82.5%
Tree:     87.1%  |  Water:     86.7%  |  Agriculture: 91.8% |  Building: 92.5%
```

### Key findings

1. **Model nhá» > model lá»›n** â€” Lightweight DAE (12.82M) tháº¯ng táº¥t cáº£ models lá»›n hÆ¡n
2. **Pretrained khÃ´ng giÃºp Ã­ch** â€” Input 11 channels khÃ¡c ImageNet, pretrained weights bá»‹ mismatch
3. **Dual-encoder phá»©c táº¡p hÃ³a** â€” TÃ¡ch RGB/label encoder (39.1M) kÃ©m hÆ¡n single-encoder (12.82M)
4. **Diffusion chÆ°a hiá»‡u quáº£** â€” 20 epochs quÃ¡ Ã­t, approach phá»©c táº¡p hÆ¡n nhiá»u so vá»›i DAE
5. **CE + Dice + Boundary loss** â€” Káº¿t há»£p 3 loss giÃºp báº£o toÃ n ranh giá»›i class tá»‘t

---

## âš™ï¸ Loss Function

```
Total Loss = CE Loss Ã— 1.0 + Dice Loss Ã— 1.0 + Boundary Loss Ã— 0.5
```

- **CrossEntropy Loss:** Pixel-wise classification
- **Dice Loss:** Overlap-based, xá»­ lÃ½ class imbalance
- **Boundary Loss:** Sobel edge detection trÃªn prediction vs target, báº£o toÃ n biÃªn

---

## ğŸ’» Hardware

| Component | Spec |
|-----------|------|
| GPU | NVIDIA L4 (23GB VRAM) |
| CPU | AMD EPYC 7R13 |
| RAM | 16GB |
| CUDA | 12.1 |
| PyTorch | 2.5.1 |
| Platform | AWS EC2 |

---

## ğŸ“„ License

Project phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c thuáº­t â€” Äá»“ Ã¡n tá»‘t nghiá»‡p HCMUTE 2026.

## ğŸ‘¤ TÃ¡c giáº£

**Tráº§n Duy VÆ°Æ¡ng** â€” MSSV: 22139078  
Khoa Äiá»‡n - Äiá»‡n tá»­, ÄH SÆ° pháº¡m Ká»¹ thuáº­t TP.HCM  
ChuyÃªn ngÃ nh: Há»‡ thá»‘ng nhÃºng vÃ  IoT
